{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Generator.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOutnks7aiR/anpRNP56hV7"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"DLE1Y_hTPvxx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"32fda53d-abd4-4f9c-a938-d9222172aba9","executionInfo":{"status":"ok","timestamp":1580461106170,"user_tz":-540,"elapsed":789,"user":{"displayName":"後藤拓也","photoUrl":"","userId":"13365501340226528906"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fo9mjX19QD9g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5e0fe356-d824-42f5-bfec-4b765cadf801","executionInfo":{"status":"ok","timestamp":1580461108417,"user_tz":-540,"elapsed":679,"user":{"displayName":"後藤拓也","photoUrl":"","userId":"13365501340226528906"}}},"source":["%cd \"/content/drive/My Drive/Colab Notebooks/slGan\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/slGan\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lBrUEiBTQOGb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d408b027-5f6e-43ad-e2f5-888de8f020ff","executionInfo":{"status":"ok","timestamp":1580461124755,"user_tz":-540,"elapsed":629,"user":{"displayName":"後藤拓也","photoUrl":"","userId":"13365501340226528906"}}},"source":["%pwd"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/Colab Notebooks/slGan'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"voIcomMvQQh2","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x\n","import tensorflow as tf\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nVryCXtyRHUr","colab_type":"code","colab":{}},"source":["def batch_norm(X, scale, offset, axes, is_train, device_name='/cpu:0'):\n","    # 予測のときにはそのまんまの値を返す\n","    if is_train is False:\n","        return X\n","\n","    epsilon = 1e-5\n","    with tf.device(device_name):\n","        mean, variance = tf.nn.moments(X, axes)\n","        bn = tf.nn.batch_normalization(X, mean, variance, offset, scale,epsilon)\n","\n","    return bn\n","\n","# dataをreadするクラス \n","class Generator(): \n","    def __init__(self):\n","\n","        #vgg16_model = VGG16(\n","        #    weights = 'imagenet',\n","        #    include_top = False,\n","        #    input_shape = (256, 192, 3)   \n","        #)\n","        #self.encoder_first = torchvision.models.vgg16(pretrained=True).features[:17] # 重み固定して使う部分\n","        #self.encoder_last = torchvision.models.vgg16(pretrained=True).features[17:-1] # 学習する部分\n","        #self.encoder_first = vgg16_model.input\n","        #for layer in model.layers[:17]: # 重み固定して使う部分\n","        #    layer.trainable = False\n","        #self.encoder_last = vgg16_model.output\n","        # Generator parameter\n","\n","        self.gen_w0 = tf.Variable(\n","            tf.random_normal(\n","                shape=[100,4*4*256], stddev=0.02, dtype=tf.float32),\n","            name=\"gen_w0\")\n","\n","        self.gen_b0 = tf.Variable(\n","            tf.random_normal(\n","                shape=[4*4*256], stddev=0.02, dtype=tf.float32),\n","            name=\"gen_b0\")    \n","\n","        self.gen_w1 = tf.Variable(\n","            tf.random_normal(\n","                shape=[4, 4, 128, 256], stddev=0.02, dtype=tf.float32),\n","            name=\"gen_w1\")\n","\n","        self.gen_b1 = tf.Variable(\n","            tf.random_normal(\n","                shape=[128], stddev=0.02, dtype=tf.float32),\n","            name=\"gen_b1\")\n","\n","        self.gen_w2 = tf.Variable(\n","            tf.random_normal(\n","                shape=[4, 4, 64, 128], stddev=0.02, dtype=tf.float32),\n","            name=\"gen_w2\")\n","\n","        self.gen_b2 = tf.Variable(\n","            tf.random_normal(\n","                shape=[64], stddev=0.02, dtype=tf.float32),\n","            name=\"gen_b2\")\n","\n","        self.gen_w3 = tf.Variable(\n","            tf.random_normal(\n","                shape=[4, 4, 1, 64], stddev=0.02, dtype=tf.float32),\n","            name=\"gen_w3\")\n","\n","        self.gen_b3 = tf.Variable(\n","            tf.random_normal(\n","                shape=[1], stddev=0.02, dtype=tf.float32),\n","            name=\"gen_b3\")          \n","\n","        self.gen_scale_w1 = tf.Variable(\n","            tf.ones([128]), name=\"gen_scale_w1\")\n","        self.gen_offset_w1 = tf.Variable(\n","            tf.zeros([128]), name=\"gen_offset_w1\")\n","\n","        self.gen_scale_w2 = tf.Variable(\n","            tf.ones([64]), name=\"gen_scale_w2\")\n","        self.gen_offset_w2 = tf.Variable(\n","            tf.zeros([64]), name=\"gen_offset_w2\")\n","\n","        self.keep_prob = tf.placeholder(tf.float32)\n","        self.batch_size = tf.placeholder(tf.int32)\n","\n","    def run(self, z, is_train):\n","\n","        h0 = tf.reshape(tf.nn.relu(tf.nn.xw_plus_b(z, self.gen_w0, self.gen_b0)),[-1,4,4,256])\n","\n","        gen_conv1 = tf.nn.conv2d_transpose(\n","                value=h0,\n","                filter=self.gen_w1,\n","                output_shape=[self.batch_size,7,7,128],\n","                strides=[1, 2, 2, 1],\n","                padding='SAME')+self.gen_b1\n","\n","        h1 = tf.nn.leaky_relu(batch_norm(gen_conv1, self.gen_scale_w1, self.gen_offset_w1,\n","                        [0, 1, 2], is_train, device_name),alpha=0.2)\n","\n","        gen_conv2 = tf.nn.conv2d_transpose(\n","                value=h1,\n","                filter=self.gen_w2,\n","                output_shape=[self.batch_size,14,14,64],\n","                strides=[1, 2, 2, 1],\n","                padding='SAME')+self.gen_b2\n","\n","        h2 = tf.nn.leaky_relu(batch_norm(gen_conv2, self.gen_scale_w2, self.gen_offset_w2,\n","                                          [0, 1, 2], is_train, device_name),alpha=0.2)\n","\n","        gen_conv3 = tf.nn.tanh(\n","            tf.nn.conv2d_transpose(\n","                value=h2,\n","                filter=self.gen_w3,\n","                output_shape=[self.batch_size,28,28,1],\n","                strides=[1, 2, 2, 1],\n","                padding='SAME')+self.gen_b3)\n","\n","        return gen_conv3\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-YbfzyETYJnZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}