{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_DCGAN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMWkKpVZCrsjrYPR8yOo1Tq"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"-OcblPYQ59wE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"a449c259-c091-4e47-da5a-ebb33d5ffe1c","executionInfo":{"status":"ok","timestamp":1580474259228,"user_tz":-540,"elapsed":654,"user":{"displayName":"後藤拓也","photoUrl":"","userId":"13365501340226528906"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"leEu96M26Dp-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"eba9a49d-d083-47a1-8fad-bb2630d0b11a","executionInfo":{"status":"ok","timestamp":1580474262913,"user_tz":-540,"elapsed":757,"user":{"displayName":"後藤拓也","photoUrl":"","userId":"13365501340226528906"}}},"source":["%cd \"/content/drive/My Drive/Colab Notebooks/slGan\""],"execution_count":10,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/slGan\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WuiywWlI6MRJ","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V4R1a13Y6WcZ","colab_type":"code","colab":{}},"source":["import time\n","from pathlib import Path\n","from PIL import Image\n","from tensorflow.contrib.learn.python.learn.datasets import mnist\n","import csv"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"my5s0ctP6Z4O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":355},"outputId":"dc517ca7-01b0-4572-f655-10a187530857","executionInfo":{"status":"ok","timestamp":1580474267735,"user_tz":-540,"elapsed":1248,"user":{"displayName":"後藤拓也","photoUrl":"","userId":"13365501340226528906"}}},"source":["dataset = mnist.read_data_sets('MNIST_data', one_hot=True)\n","img = np.array(dataset.train.images[753])\n","plt.imshow(img.reshape(28,28))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f38ebae3cc0>"]},"metadata":{"tags":[]},"execution_count":13},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Bb5u5FET6d4A","colab_type":"code","colab":{}},"source":["def batch_norm(X, scale, offset, axes, is_train):\n","    # 予測のときにはそのまんまの値を返す\n","    if is_train is False:\n","        return X\n","\n","    epsilon = 1e-5\n","    mean, variance = tf.nn.moments(X, axes)\n","    bn = tf.nn.batch_normalization(X, mean, variance, offset, scale,epsilon)\n","\n","    return bn\n","\n","class Generator():\n","    def __init__(self):\n","\n","        # Generator parameter\n","        self.gen_w0 = tf.Variable(\n","            tf.random_normal(\n","                shape=[100,4*4*256], stddev=0.02, dtype=tf.float32),\n","            name=\"gen_w0\")\n","\n","        self.gen_b0 = tf.Variable(\n","            tf.random_normal(\n","                shape=[4*4*256], stddev=0.02, dtype=tf.float32),\n","            name=\"gen_b0\")    \n","                  \n","        self.gen_w1 = tf.Variable(\n","            tf.random_normal(\n","                shape=[4, 4, 128, 256], stddev=0.02, dtype=tf.float32),\n","            name=\"gen_w1\")\n","        \n","        self.gen_b1 = tf.Variable(\n","            tf.random_normal(\n","                shape=[128], stddev=0.02, dtype=tf.float32),\n","            name=\"gen_b1\")\n","        \n","        self.gen_w2 = tf.Variable(\n","            tf.random_normal(\n","                shape=[4, 4, 64, 128], stddev=0.02, dtype=tf.float32),\n","            name=\"gen_w2\")\n","        \n","        self.gen_b2 = tf.Variable(\n","            tf.random_normal(\n","                shape=[64], stddev=0.02, dtype=tf.float32),\n","            name=\"gen_b2\")\n","        \n","        self.gen_w3 = tf.Variable(\n","            tf.random_normal(\n","                shape=[4, 4, 1, 64], stddev=0.02, dtype=tf.float32),\n","            name=\"gen_w3\")\n","        \n","        self.gen_b3 = tf.Variable(\n","            tf.random_normal(\n","                shape=[1], stddev=0.02, dtype=tf.float32),\n","            name=\"gen_b3\")          \n","        \n","        self.gen_scale_w0 = tf.Variable(\n","            tf.ones([256]), name=\"gen_scale_w0\")\n","        self.gen_offset_w0 = tf.Variable(\n","            tf.zeros([256]), name=\"gen_offset_w0\")\n","        \n","        self.gen_scale_w1 = tf.Variable(\n","            tf.ones([128]), name=\"gen_scale_w1\")\n","        self.gen_offset_w1 = tf.Variable(\n","            tf.zeros([128]), name=\"gen_offset_w1\")\n","\n","        self.gen_scale_w2 = tf.Variable(\n","            tf.ones([64]), name=\"gen_scale_w2\")\n","        self.gen_offset_w2 = tf.Variable(\n","            tf.zeros([64]), name=\"gen_offset_w2\")\n","\n","        self.keep_prob = tf.placeholder(tf.float32)\n","        self.batch_size = tf.placeholder(tf.int32)\n","            \n","    def run(self, z, is_train):\n","\n","        h0 = tf.reshape(tf.nn.relu(tf.nn.xw_plus_b(z, self.gen_w0, self.gen_b0)),[-1,4,4,256])\n","                    \n","        gen_conv1 = tf.nn.conv2d_transpose(\n","                value=h0,\n","                filter=self.gen_w1,\n","                output_shape=[self.batch_size,7,7,128],\n","                strides=[1, 2, 2, 1],\n","                padding='SAME')+self.gen_b1\n","        \n","        h1 = tf.nn.leaky_relu(batch_norm(gen_conv1, self.gen_scale_w1, self.gen_offset_w1,\n","                        [0, 1, 2], is_train),alpha=0.2)\n","        \n","        gen_conv2 = tf.nn.conv2d_transpose(\n","                value=h1,\n","                filter=self.gen_w2,\n","                output_shape=[self.batch_size,14,14,64],\n","                strides=[1, 2, 2, 1],\n","                padding='SAME')+self.gen_b2\n","            \n","        h2 = tf.nn.leaky_relu(batch_norm(gen_conv2, self.gen_scale_w2, self.gen_offset_w2,\n","                                          [0, 1, 2], is_train),alpha=0.2)\n","        \n","        gen_conv3 = tf.nn.tanh(\n","            tf.nn.conv2d_transpose(\n","                value=h2,\n","                filter=self.gen_w3,\n","                output_shape=[self.batch_size,28,28,1],\n","                strides=[1, 2, 2, 1],\n","                padding='SAME')+self.gen_b3)\n","        \n","        return gen_conv3\n","\n","class Discrimitor():\n","    def __init__(self):\n","        # Discrimitor parameter\n","        self.dis_w1 = tf.Variable(\n","            tf.random_normal(\n","                shape=[4, 4, 1, 64], stddev=0.02, dtype=tf.float32),\n","            name=\"dis_w1\")\n","        \n","        self.dis_b1 = tf.Variable(\n","            tf.random_normal(\n","                shape=[64], stddev=0.02, dtype=tf.float32),\n","            name=\"dis_b1\")\n","        \n","        self.dis_w2 = tf.Variable(\n","            tf.random_normal(\n","                shape=[4, 4, 64, 128], stddev=0.02, dtype=tf.float32),\n","            name=\"dis_w2\")\n","        \n","        self.dis_b2 = tf.Variable(\n","            tf.random_normal(\n","                shape=[128], stddev=0.02, dtype=tf.float32),\n","            name=\"dis_b2\")\n","        \n","        self.dis_w3 = tf.Variable(\n","            tf.random_normal(\n","                shape=[4, 4, 128, 256], stddev=0.02, dtype=tf.float32),\n","            name=\"dis_w3\")\n","        \n","        self.dis_b3 = tf.Variable(\n","            tf.random_normal(\n","                shape=[256], stddev=0.02, dtype=tf.float32),\n","            name=\"dis_b3\")\n","        \n","        self.dis_w4 = tf.Variable(\n","            tf.random_normal(\n","                shape=[4*4*256,1], stddev=0.02, dtype=tf.float32),\n","            name=\"dis_w4\")\n","        \n","        self.dis_b4 = tf.Variable(\n","            tf.random_normal(\n","                shape=[1], stddev=0.02, dtype=tf.float32),\n","            name=\"dis_b4\")\n","\n","    def run(self, x, is_train):\n","        input_layer = tf.reshape(x, [-1, 28, 28, 1])\n","        dis_conv1 = tf.nn.conv2d(\n","                input=input_layer,\n","                filter=self.dis_w1,\n","                strides=[1, 2, 2, 1],\n","                padding='SAME')+self.dis_b1\n","        \n","        h1 = tf.nn.leaky_relu(dis_conv1,alpha=0.2)\n","\n","        dis_conv2 = tf.nn.conv2d(\n","                input=h1,\n","                filter=self.dis_w2,\n","                strides=[1, 2, 2, 1],\n","                padding='SAME')+self.dis_b2\n","\n","        h2 =tf.nn.leaky_relu(dis_conv2,alpha=0.2)     \n","    \n","        dis_conv3 = tf.nn.conv2d(\n","                input=h2,\n","                filter=self.dis_w3,\n","                strides=[1, 2, 2, 1],\n","                padding='SAME')+self.dis_b3\n","        \n","        h3 = tf.nn.leaky_relu(dis_conv3,alpha=0.2)\n","  \n","        h3_flat = tf.reshape(h3,[-1,4*4*256])\n","        fc = tf.nn.sigmoid(tf.nn.xw_plus_b(h3_flat,weights=self.dis_w4,biases=self.dis_b4))\n","            \n","        return fc\n","\n","\n","class DCGAN():\n","    def __init__(self):\n","\n","        self.G_is_train = tf.placeholder(tf.bool)\n","        self.D_is_train = tf.placeholder(tf.bool)\n","        self.input_X = tf.placeholder(tf.float32, shape=(None, 28 * 28))\n","\n","        # t0は0のラベルを格納し、t1は1のラベルを格納する\n","        self.label_t0 = tf.placeholder(tf.float32, shape=(None, 1))\n","        self.label_t1 = tf.placeholder(tf.float32, shape=(None, 1))\n","\n","        # Generator\n","        self.generator = Generator()\n","        # 生成モデルに必要なノイズの入れ物\n","        self.gen_z = tf.placeholder(tf.float32, shape=(None, 100))\n","        # Discrimitor\n","        self.discrimitor = Discrimitor()\n","\n","        # weight decay\n","        gen_norm_term = tf.nn.l2_loss(self.generator.gen_w2) + tf.nn.l2_loss(self.generator.gen_w3)\n","        gen_lambda_ = 0.001\n","\n","        dis_norm_term = tf.nn.l2_loss(self.discrimitor.dis_w2) + tf.nn.l2_loss(self.discrimitor.dis_w3)\n","        dis_lambda_ = 0.001\n","\n","        # 訓練データの識別予測\n","        input_X = self.discrimitor.run(\n","            self.input_X,\n","            is_train=self.D_is_train)\n","        \n","        # 生成されたデータの識別予測\n","        generated_X = self.discrimitor.run( self.generator.run(z=self.gen_z, is_train=self.G_is_train), is_train=self.D_is_train)\n","\n","        self.dis_entropy_X = tf.nn.sigmoid_cross_entropy_with_logits(labels=self.label_t1, logits=input_X)\n","        self.dis_entropy_G = tf.nn.sigmoid_cross_entropy_with_logits(labels=self.label_t0, logits=generated_X)\n","        self.dis_loss = tf.reduce_mean(\n","            self.dis_entropy_X + self.dis_entropy_G\n","        ) + dis_norm_term * dis_lambda_\n","\n","        self.gen_entropy = tf.nn.sigmoid_cross_entropy_with_logits(\n","            labels=self.label_t1, logits=generated_X)\n","        self.gen_loss = tf.reduce_mean(\n","            self.gen_entropy) #+ gen_norm_term * gen_lambda_\n","\n","        # 最適化する際にDならDのみのパラメータを、GならGのみのパラメータを更新するようにしたいのでモデル別の変数を取得する\n","        dis_vars = [\n","            x for x in tf.trainable_variables() if \"dis_\" in x.name\n","        ]\n","        gen_vars = [\n","            x for x in tf.trainable_variables() if \"gen_\" in x.name\n","        ]\n","\n","        # 識別モデルDの最適化\n","        self.opt_d = tf.train.AdamOptimizer(0.0002,beta1=0.1).minimize(\n","                self.dis_loss, var_list=[dis_vars])\n","        # 生成モデルGの最適化\n","        self.opt_g = tf.train.AdamOptimizer(0.0002, beta1=0.5).minimize(\n","                self.gen_loss, var_list=[gen_vars])\n","                                   \n","    def train(self,\n","              X_train=None,\n","              batch_size=100,\n","              epoch_num=1000,\n","              imgpath='./mnist_DCGAN_images/',\n","              ckptpath='./mnist_DCGAN_checkpoints/',\n","              log_file='mnist_DCGAN_loss_log.csv',\n","              init=False):\n","\n","        if X_train is None:\n","            raise TypeError(\"X_train is None\")\n","\n","        # 訓練途中で生成データを作成して保存したいのでその保存先の作成\n","        p = Path(imgpath)\n","        if not (p.is_dir()):\n","            p.mkdir()\n","\n","        # モデルパラメータのチェックポイントの保存先\n","        ckpt_p = Path(ckptpath)\n","        if not (ckpt_p.is_dir()):\n","            ckpt_p.mkdir()\n","\n","        config = tf.ConfigProto()\n","        config.gpu_options.allow_growth = True\n","\n","        saver = tf.train.Saver()\n","\n","        sess = tf.Session()\n","\n","        if (init):\n","            sess.run(tf.global_variables_initializer())\n","            print('Initialize')\n","\n","        ckpt = tf.train.get_checkpoint_state(str(ckpt_p.absolute()))\n","        if ckpt:\n","            # checkpointファイルから最後に保存したモデルへのパスを取得する\n","            last_model = ckpt.model_checkpoint_path\n","            print(\"load {0}\".format(last_model))\n","            # 学習済みモデルを読み込む\n","            saver.restore(sess, last_model)\n","\n","        step = len(X_train) // batch_size\n","        #step = mnist.train.num_examples // batch_size\n","\n","        # 正解ラベルのミニバッチ\n","        t1_batch = np.ones((batch_size, 1), dtype=np.float32)\n","        t0_batch = np.zeros((batch_size, 1), dtype=np.float32)\n","\n","        for epoch in range(epoch_num):\n","\n","            perm = np.random.permutation(len(X_train))\n","            # １エポックごとにかかる時間の計測\n","            start = time.time()\n","            for k in range(step):\n","                #X_batch = mnist.train.next_batch(batch_size)[0] /255.\n","                X_batch = X_train[perm][k * batch_size:(k + 1) * batch_size]\n","\n","                # Train Discrimitor\n","                # ノイズ事前分布からノイズをミニバッチ分取得\n","                noise_z = np.random.uniform(\n","                    -1, 1, size=[batch_size,100]).astype(np.float32)\n","\n","                sess.run(\n","                    self.opt_d,\n","                    feed_dict={\n","                        self.input_X: X_batch,\n","                        self.D_is_train: True,\n","                        self.G_is_train: False,\n","                        self.gen_z: noise_z,\n","                        self.generator.keep_prob: 1.0,\n","                        self.generator.batch_size: batch_size,\n","                        self.label_t1: t1_batch,\n","                        self.label_t0: t0_batch\n","                    })\n","\n","                if k % 1 == 0:\n","                    # Train Generator\n","                    # ノイズ事前分布からノイズをミニバッチ分取得\n","                    noise_z = np.random.uniform(\n","                        -1, 1, size=[batch_size,100]).astype(np.float32)\n","                    sess.run(\n","                        self.opt_g,\n","                        feed_dict={\n","                            self.gen_z: noise_z,\n","                            self.D_is_train: False,\n","                            self.G_is_train: True,\n","                            self.generator.keep_prob: 0.5,\n","                            self.generator.batch_size: batch_size,\n","                            self.label_t1: t1_batch\n","                        })\n","\n","            # 1epoch終了時の損失を表示\n","            noise_z = np.random.uniform(\n","                -1, 1, size=[batch_size,100]).astype(np.float32)\n","            train_dis_loss = sess.run(\n","                self.dis_loss,\n","                feed_dict={\n","                    self.input_X: X_batch,\n","                    self.D_is_train: False,\n","                    self.G_is_train: False,\n","                    self.gen_z: noise_z,\n","                    self.generator.keep_prob: 1.0,\n","                    self.generator.batch_size: batch_size,\n","                    self.label_t1: t1_batch,\n","                    self.label_t0: t0_batch\n","                })\n","\n","            train_gen_loss = sess.run(\n","                self.gen_loss,\n","                feed_dict={\n","                    self.gen_z: noise_z,\n","                    self.D_is_train: False,\n","                    self.G_is_train: False,\n","                    self.generator.keep_prob: 1.0,\n","                    self.generator.batch_size: batch_size,\n","                    self.label_t1: t1_batch\n","                })\n","            print(\n","                \"[Train] epoch: %d, dis loss: %f , gen loss : %f  Time : %f\" %\n","                (epoch, train_dis_loss, train_gen_loss, time.time() - start))\n","\n","            # ファイルオープン\n","            f = open(log_file, 'a')\n","            log_writer = csv.writer(f, lineterminator='\\n')\n","            loss_list = []\n","            loss_list.append(epoch)\n","            loss_list.append(train_dis_loss)\n","            loss_list.append(train_gen_loss)\n","            # 損失の値を書き込む\n","            log_writer.writerow(loss_list)\n","            f.close()\n","\n","            saver.save(sess, str(ckpt_p.absolute()) + '/DCGAN-mnist')\n","\n","            # 10epoch終了毎に生成モデルから1枚の画像を生成する\n","            if epoch % 2 == 0:\n","                noise_z = np.random.uniform(\n","                    -1,1, size=[5,100]).astype(np.float32)\n","\n","                z_const = tf.constant(noise_z, dtype=tf.float32)\n","                gen_imgs = ((sess.run(\n","                    self.generator.run(z_const, is_train=False),\n","                    feed_dict={self.generator.keep_prob: 1.0,self.generator.batch_size: 5})* 0.5)+0.5)*255.\n","                for i in range(0,5):\n","                    Image.fromarray(gen_imgs[i].reshape(\n","                        28, 28)).convert('RGB').save(\n","                            str(p.absolute()) +\n","                            '/generate_img_epoch{0}_{1}.jpg'.format(epoch,i))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3IoHrTx6zwj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"d8dd62c9-fe7d-4a3b-900b-d3b23d14fc5c","executionInfo":{"status":"ok","timestamp":1580474280225,"user_tz":-540,"elapsed":718,"user":{"displayName":"後藤拓也","photoUrl":"","userId":"13365501340226528906"}}},"source":["X_train = (dataset.train.images - 0.5 ) / 0.5\n","len(X_train)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["55000"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"KcVkAM2S7jxq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":953},"outputId":"4cad4abf-6833-402c-d949-d86db2253295","executionInfo":{"status":"ok","timestamp":1580498343387,"user_tz":-540,"elapsed":14571190,"user":{"displayName":"後藤拓也","photoUrl":"","userId":"13365501340226528906"}}},"source":["model = DCGAN()\n","model.train(\n","    X_train=X_train[:30000],\n","    batch_size=100,\n","    epoch_num=51,\n","    init=True)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Initialize\n","[Train] epoch: 0, dis loss: 1.495829 , gen loss : 0.691980  Time : 465.975002\n","[Train] epoch: 1, dis loss: 1.465094 , gen loss : 0.693017  Time : 466.687557\n","[Train] epoch: 2, dis loss: 1.440944 , gen loss : 0.692981  Time : 467.580492\n","[Train] epoch: 3, dis loss: 1.423931 , gen loss : 0.692743  Time : 468.460238\n","[Train] epoch: 4, dis loss: 1.675496 , gen loss : 0.314967  Time : 466.270964\n","[Train] epoch: 5, dis loss: 1.252660 , gen loss : 0.576094  Time : 466.938187\n","[Train] epoch: 6, dis loss: 1.192623 , gen loss : 0.608426  Time : 466.730093\n","[Train] epoch: 7, dis loss: 1.421707 , gen loss : 0.693088  Time : 468.103709\n","[Train] epoch: 8, dis loss: 1.412241 , gen loss : 0.693083  Time : 467.351118\n","[Train] epoch: 9, dis loss: 1.406177 , gen loss : 0.693017  Time : 467.369264\n","[Train] epoch: 10, dis loss: 1.339267 , gen loss : 0.495425  Time : 472.748704\n","[Train] epoch: 11, dis loss: 1.297050 , gen loss : 0.579046  Time : 467.374798\n","[Train] epoch: 12, dis loss: 1.281781 , gen loss : 0.653854  Time : 470.539572\n","[Train] epoch: 13, dis loss: 1.363613 , gen loss : 0.630027  Time : 471.784915\n","[Train] epoch: 14, dis loss: 1.340158 , gen loss : 0.635496  Time : 467.773564\n","[Train] epoch: 15, dis loss: 1.389427 , gen loss : 0.542160  Time : 467.677499\n","[Train] epoch: 16, dis loss: 1.376959 , gen loss : 0.673307  Time : 469.137955\n","[Train] epoch: 17, dis loss: 1.397979 , gen loss : 0.677037  Time : 468.294610\n","[Train] epoch: 18, dis loss: 1.384811 , gen loss : 0.678800  Time : 468.470422\n","[Train] epoch: 19, dis loss: 1.365162 , gen loss : 0.587955  Time : 468.279881\n","[Train] epoch: 20, dis loss: 1.412183 , gen loss : 0.688110  Time : 471.739711\n","[Train] epoch: 21, dis loss: 1.418718 , gen loss : 0.687608  Time : 475.428978\n","[Train] epoch: 22, dis loss: 1.333984 , gen loss : 0.590821  Time : 469.703193\n","[Train] epoch: 23, dis loss: 1.340507 , gen loss : 0.558051  Time : 470.111646\n","[Train] epoch: 24, dis loss: 1.371534 , gen loss : 0.529700  Time : 472.333475\n","[Train] epoch: 25, dis loss: 1.401474 , gen loss : 0.686125  Time : 471.329702\n","[Train] epoch: 26, dis loss: 1.418818 , gen loss : 0.690817  Time : 475.811152\n","[Train] epoch: 27, dis loss: 1.394492 , gen loss : 0.685560  Time : 467.708600\n","[Train] epoch: 28, dis loss: 1.317353 , gen loss : 0.566663  Time : 467.958514\n","[Train] epoch: 29, dis loss: 1.330827 , gen loss : 0.603670  Time : 467.392207\n","[Train] epoch: 30, dis loss: 1.371713 , gen loss : 0.664250  Time : 470.110474\n","[Train] epoch: 31, dis loss: 1.319859 , gen loss : 0.646474  Time : 466.398799\n","[Train] epoch: 32, dis loss: 1.316368 , gen loss : 0.624971  Time : 462.373055\n","[Train] epoch: 33, dis loss: 1.353112 , gen loss : 0.667244  Time : 464.178295\n","[Train] epoch: 34, dis loss: 1.323848 , gen loss : 0.555745  Time : 462.667609\n","[Train] epoch: 35, dis loss: 1.339745 , gen loss : 0.646727  Time : 463.488231\n","[Train] epoch: 36, dis loss: 1.306670 , gen loss : 0.596110  Time : 466.617841\n","[Train] epoch: 37, dis loss: 1.311135 , gen loss : 0.574563  Time : 466.238341\n","[Train] epoch: 38, dis loss: 1.352317 , gen loss : 0.592503  Time : 465.397768\n","[Train] epoch: 39, dis loss: 1.412758 , gen loss : 0.689828  Time : 465.841277\n","[Train] epoch: 40, dis loss: 1.360310 , gen loss : 0.674405  Time : 466.205449\n","[Train] epoch: 41, dis loss: 1.350554 , gen loss : 0.663051  Time : 469.074675\n","[Train] epoch: 42, dis loss: 1.416441 , gen loss : 0.469075  Time : 468.168095\n","[Train] epoch: 43, dis loss: 1.346943 , gen loss : 0.654752  Time : 470.374321\n","[Train] epoch: 44, dis loss: 1.326705 , gen loss : 0.584238  Time : 471.351200\n","[Train] epoch: 45, dis loss: 1.347463 , gen loss : 0.561111  Time : 469.774144\n","[Train] epoch: 46, dis loss: 1.327254 , gen loss : 0.625357  Time : 467.021535\n","[Train] epoch: 47, dis loss: 1.368010 , gen loss : 0.675999  Time : 466.430872\n","[Train] epoch: 48, dis loss: 1.358220 , gen loss : 0.645600  Time : 466.315131\n","[Train] epoch: 49, dis loss: 1.394647 , gen loss : 0.673698  Time : 468.765857\n","[Train] epoch: 50, dis loss: 1.363179 , gen loss : 0.536549  Time : 467.779990\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YfpV4i667ocp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}